

UsedDatasetConfig:
  train_dataset_config: 
    name_manifest_path: /data/lipsync/xgyang/E2EGeneration/V1/cache_dir/hubert/neural/data_train.txt
    static_feature_dir: /data/lipsync/xgyang/e2e_data/static_feature/layer6/hubert_60
    ctrl_label_dir: /data/lipsync/xgyang/e2e_data/normalized_extracted_ctrl_labels
    max_keep_feature_size:
    min_keep_feature_size:
  validate_dataset_config:
    name_manifest_path: /data/lipsync/xgyang/E2EGeneration/V1/cache_dir/hubert/neural/data_validate.txt
    static_feature_dir: /data/lipsync/xgyang/e2e_data/static_feature/layer6/hubert_60
    ctrl_label_dir: /data/lipsync/xgyang/e2e_data/normalized_extracted_ctrl_labels
    max_keep_feature_size:
    min_keep_feature_size:

TrainingConfig:
  # weight_decay: 0.
  gradient_clip_val:
  n_epochs: 1000
  devices: [0]
  epoch_milestones: [200, 500]
  warmup_epochs: 20
  check_val_every_n_epoch: 
  val_check_interval: 750
  checkpoint_config:
    save_checkpoint: True
    checkpoint_dir: "/data/lipsync/xgyang/E2EGeneration/V1/checkpoint_dir/model_1/hubert_layer6/all_pca_v1"
    checkpoint_sub_name: "{epoch}-{step}-{mouth_l1_validate_loss:.4f}"
    monitor: "mouth_l1_validate_loss"
    save_last: True
    save_top_k: 2
    save_weights_only: False
    mode: "min"
    every_n_epochs: 1
    every_n_train_steps: 
    save_on_train_epoch_end: False
  phn_embedding_config:
    add_phn: True
    phn_dir: /data/lipsync/xgyang/e2e_data/aligned_phonemes
    phn_num: 63
    phn_padding_idx: 0
    phn_directly_pad: True
    phn_flatten_pad: False
  pca_config:
    learn_pca: True
    pca_label_dir: /data/lipsync/xgyang/e2e_data/yingrao/dataproc/crop_pca
    n_pca_channels: 134
    
Model1Config:
  pre_lnorm: True
